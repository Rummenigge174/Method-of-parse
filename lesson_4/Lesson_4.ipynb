{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбор новостей с сайтов Yandex.ru, Mail.ru, Lenta.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from lxml import html\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "header = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_to_yandex():\n",
    "    response = requests.get('https://yandex.ru/news/', headers=header)\n",
    "    dom = html.fromstring(response.text)\n",
    "\n",
    "    news = []\n",
    "    items = dom.xpath(\"//div[@class='stories-set stories-set_main_no stories-set_pos_1']//td\")\n",
    "    for item in items:\n",
    "        new = {}\n",
    "        source1 = item.xpath(\".//div[@class='story__info']/div/text()\")\n",
    "        source_news = re.findall(r'([^\\d+:\\d+]+|^\\w+\\.+\\w+)', source1[0])\n",
    "        name = item.xpath(\".//h2/a/text()\")\n",
    "        link = item.xpath(\".//h2/a/@href\")\n",
    "        time_news = re.findall(r'\\d+:\\d+', source1[0])\n",
    "        date_news = datetime.datetime.today().strftime('%d/%m/%Y')\n",
    "\n",
    "        if ' вчера\\xa0в\\xa0' in source_news: #Если новость вчерашняя вычетаем один день из даты\n",
    "            a = date_news.split('/')\n",
    "            d = int(a[0]) - 1\n",
    "            m = int(a[1])\n",
    "            y = int(a[2])\n",
    "            date_news = datetime.date(y, m, d).strftime('%d/%m/%Y')\n",
    "            date_time_news = date_news + ' ' + time_news[0] +' (Вчера)'#В выводе добавляем пометку (Вчера)\n",
    "            source_news.pop(1)\n",
    "        else:\n",
    "            date_time_news = date_news + ' ' + time_news[0]\n",
    "\n",
    "        new['link'] = link[0]\n",
    "        new['date'] = date_time_news\n",
    "        new['name'] = name[0]\n",
    "        new['source'] = source_news[0]\n",
    "        news.append(new)\n",
    "        with open('news_yandex.json', 'w') as f:\n",
    "            json.dump(news, f)\n",
    "\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_to_mailru():\n",
    "    response = requests.get('https://sportmail.ru/',\n",
    "                            headers=header)\n",
    "    dom = html.fromstring(response.text)\n",
    "    news = []\n",
    "    items = dom.xpath(\"//div[@class='block']//li\")\n",
    "    for item in items:\n",
    "        new = {}\n",
    "        name = item.xpath(\"./a/text()\")\n",
    "        link = item.xpath(\"./a/@href\")\n",
    "        new['name'] = name[0].replace('\\xa0', ' ')\n",
    "        new['link'] = link[0]\n",
    "        response1 = requests.get(link[0], headers=header) #Делаем Get-запрос по ссылке новости,                                      \n",
    "        dom1 = html.fromstring(response1.text)            #чтобы \"вытянуть\" дату и источник новости.\n",
    "        items1 = dom1.xpath(\"//div[@class='breadcrumbs breadcrumbs_article js-ago-wrapper']\")\n",
    "        for item1 in items1:\n",
    "            date_news = item1.xpath(\".//span[@class='note__text breadcrumbs__text js-ago']/text()\")\n",
    "            source_news = item1.xpath(\".//span[@class='link__text']/text()\")\n",
    "            new['date'] = date_news[0]\n",
    "            new['source'] = source_news[0]\n",
    "\n",
    "        news.append(new)\n",
    "        with open('news_mailru.json', 'w') as f:\n",
    "            json.dump(news, f)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef request_to_lentaru():\n",
    "    main_link = 'https://lenta.ru'\n",
    "    response = requests.get('https://lenta.ru/rubrics/economics/',\n",
    "                            headers=header)\n",
    "    dom = html.fromstring(response.text)\n",
    "    news = []\n",
    "    items = dom.xpath(\"//div[@class='row js-content']//div[@class='item news b-tabloid__topic_news']\")\n",
    "    for item in items:\n",
    "        new = {}\n",
    "        name = item.xpath(\".//h3//span/text()\")\n",
    "        link = item.xpath(\".//h3//a/@href\")\n",
    "        date_news = item.xpath(\".//span[@class='g-date item__date']/text()\")\n",
    "        new['name'] = name[0].replace('\\xa0', ' ')\n",
    "        new['link'] = main_link + link[0]\n",
    "        new['date'] = date_news[0]\n",
    "        new['source'] = 'Lenta.ru'\n",
    "        news.append(new)\n",
    "        with open('news_lentaru.json', 'w') as f:\n",
    "            json.dump(news, f)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(request_to_yandex())\n",
    "pprint(request_to_mailru())\n",
    "pprint(request_to_lentaru())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка новостей в базу данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import pprint\n",
    "import json\n",
    "from pymongo.errors import DuplicateKeyError, BulkWriteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news_yandex.json', encoding='utf-8') as f:\n",
    "    news_yandex_list = json.load(f)\n",
    "with open('news_mailru.json', encoding='utf-8') as f:\n",
    "    news_mailru_list = json.load(f)\n",
    "with open('news_lentaru.json', encoding='utf-8') as f:\n",
    "    news_lentaru_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client['news_db']\n",
    "news_yandex = db.news_yandex\n",
    "news_mailru = db.news_mailru\n",
    "news_lentaru = db.news_lentaru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_base(news_list, collections):\n",
    "    j = 0\n",
    "    k = 0\n",
    "    for i in range(0, len(news_list)):\n",
    "        try:\n",
    "            collections.insert_one(news_list[i])\n",
    "            j += 1\n",
    "        except (DuplicateKeyError):\n",
    "            k += 1\n",
    "    print(f'В базу записано {j} уникальных документов')\n",
    "    print(f'Выявлено {k} дубликтов документов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_base(news_yandex_list, news_yandex)\n",
    "write_to_base(news_mailru_list, news_mailru)\n",
    "write_to_base(news_lentaru_list, news_lentaru)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
